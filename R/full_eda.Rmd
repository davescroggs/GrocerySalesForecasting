---
title: "Exploratory Data Analysis - "
output: github_document

knit: (function(inputFile, encoding) {
      out_dir <- "../markdowns";
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_dir=file.path(dirname(inputFile), out_dir))})
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(here)

# Read in data
train <- read_csv(here("data/train.csv"))
test <- read_csv(here("data/test.csv")) 
items <- read_csv(here("data/items.csv")) 
stores <- read_csv(here("data/stores.csv"))
transactions <- read_csv(here("data/transactions.csv"))
oil <- read_csv(here("data/oil.csv"))
holidays <- read_csv(here("data/holidays_events.csv"))
```

## Data overview

 - Train has 125 million rows and consumes a large amount of RAM. Will be challenging to visualise and model
 - All tables only have a few columns, meaning feature engineering should be a shorter process
 - 4100 sale items

```{r}
tibble(table = c("holidays", "items", "oil", "stores", "test", "train", "transactions"),
       rows = map_int(list(holidays, items, oil, stores, test, train, transactions),nrow),
       cols = map_int(list(holidays, items, oil, stores, test, train, transactions),ncol),
       `Column names` = map_chr(list(holidays, items, oil, stores, test, train, transactions),~colnames(.x) %>% paste(collapse = ", "))) %>% 
  arrange(-rows) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()
```

## Test/train

### Dates

- Train dates run from Jan 1 2013 to Aug 15 2017
- Test runs for the 16 days left in Aug 2017
- Forecasting is only for 16 days past the last training record
- All data sets are missing the 359th/360th day which is christmas day. For train, every other day of the year has at least one record, although according to the data description - "The training data does not include rows for items that had zero unit_sales for a store/date combination"



```{r}
# Create spans of integers - https://stackoverflow.com/questions/16911773/collapse-runs-of-consecutive-numbers-to-ranges
findIntRuns <- function(run){
  rundiff <- c(1, diff(run))
  difflist <- split(run, cumsum(rundiff!=1))
  unlist(lapply(difflist, function(x){
    if(length(x) %in% 1:2) as.character(x) else paste0(x[1], "-", x[length(x)])
  }), use.names=FALSE)
}

train %>% 
  transmute(date, tbl = "train") %>% 
  bind_rows(test %>% 
              transmute(date, tbl = "test")) %>% 
  distinct(date, .keep_all = TRUE) %>% 
  mutate(day = lubridate::yday(date)) %>% 
  group_by(year = year(date),tbl) %>% 
  summarise(n = n(),
            min = min(date),
            max = max(date),
            distinct_days = n_distinct(day),
            NAs = sum(is.na(day)),
            missing_days = setdiff(1:366,day) %>% findIntRuns() %>% paste(collapse = ", ")) %>% 
  arrange(min) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()
```


```{r}
train %>% 
  arrange(store_nbr, date) %>% 
  mutate(dow = lubridate::wday(date, label = TRUE)) %>% 
  group_by(store_nbr, dow) %>% 
  summarise(unit_sales_total = sum(unit_sales),
            n = n(),
            .groups = "drop") %>% 
  mutate(store_nbr = factor(store_nbr),
         store_nbr = fct_reorder(store_nbr, unit_sales_total, sum)) %>% 
  ggplot(aes(x = unit_sales_total, y = store_nbr, col = dow)) + 
  geom_point() +
  ggrepel::geom_label_repel(data = ~group_by(., dow) %>% sample_n(size = 1),
                            aes(label = dow),
                            min.segment.length = 0,nudge_x = -5000)
```


### Stores

 - Some stores have days where their sales are much larger than their median sales

```{r}
train %>% 
  group_by(store_nbr) %>% 
  summarise(qtiles = quantile(unit_sales, probs = seq(0, 1, 0.25), na.rm = FALSE,
         names = TRUE) %>% list()) %>% 
  unnest_auto(qtiles) %>% 
  pivot_longer(cols = -store_nbr) %>%
  mutate(name = factor(name,
                            levels = c("0%","25%","50%","75%","100%"),
                            ordered = T),
         store_nbr = factor(store_nbr)) %>% 
  ggplot(aes(x = value, y = fct_reorder(store_nbr,value,max), col = name)) +
  geom_point() +
  labs(x = "Unit sales",
       y = "Store number",
       title = "Unit sales by quantile",
       col = "Quantile")
```

#### Median unit sales per item

- For all stores, the median units sold per item is between 2-8. Stores sell lots of low number of items per day?

```{r}
train %>% 
  group_by(store_nbr) %>% 
  summarise(median_sales = median(unit_sales)) %>% 
  mutate(store_nbr = factor(store_nbr)) %>% 
  ggplot(aes(x = median_sales, y = fct_reorder(store_nbr,median_sales))) +
  geom_point() +
  labs(x = "Unit sales",
       y = "Store number",
       title = "Median unit sales",
       col = "Median")
```

#### Store toal sales

```{r}
total_sales <- train %>% 
  count(year = year(date), store_nbr, wt = unit_sales, name = "unit_sales") %>% 
  mutate(store_nbr = factor(store_nbr))

total_sales %>% 
  ggplot(aes(x = unit_sales, y = fct_reorder(store_nbr,unit_sales), col = factor(year))) +
  geom_point() +
  scale_color_brewer(palette = "Spectral") +
  scale_x_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  labs(x = "Total unit sales (millions)",
       y = "Store number",
       title = "Yearly total unit sales",
       col = "Year")
```



#### Store toal sales by cluster

 - Clusters contain between 

```{r}
stores %>% 
  group_by(cluster) %>% 
  summarise(n = n(),
            stores_label = paste(store_nbr, collapse = ", ")) %>% 
  mutate(cluster = factor(cluster)) %>% 
  ggplot(aes(x = n, y = fct_reorder(cluster, n))) +
  geom_col(fill = "black") +
  scale_x_continuous(breaks = 0:10) +
  geom_text(aes(label = paste("Stores:", stores_label)), hjust = 1.1, col = "white") +
  labs(x = "# of stores",
       y = "Cluster",
       title = "Number of stores contained in each cluster") +
  theme(plot.title = element_text(hjust = 0.5))
```

 - It appears as if clusters have a strong total sales relationship

```{r}
 cluster_total <- train %>% 
  left_join(stores,
            by = "store_nbr") %>% 
  count(cluster = factor(cluster), store_nbr, wt = unit_sales, name = "unit_sales") %>% 
  mutate(store_nbr = factor(store_nbr))

cluster_total %>% 
  ggplot(aes(x = unit_sales, y = fct_reorder(cluster,unit_sales))) +
  geom_point() +
  scale_color_brewer(palette = "Spectral") +
  scale_x_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  labs(x = "Total unit sales (millions)",
       title = "Yearly total unit sales",
       y = "Cluster")  +
  theme(plot.title = element_text(hjust = 0.5))
```



### Items

#### Which items are in the most/least number of stores

- Show if the store has ever sold each item, counted by family

```{r}
train %>% 
  distinct(store_nbr, item_nbr) %>% 
  left_join(items)

t <- .Last.value

t %>% 
  count(family) %>% 
  mutate(type = "Store totals") %>% 
  bind_rows(items %>% 
  count(family) %>% 
    mutate(type = "Item totals")) %>% 
  ggplot(aes(x = n, y = fct_reorder(family, n))) +
  geom_col() +
  labs(x = "# of items",
       title = "The number of items in each family",
       y = "Family")  +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_grid(.~type, scales = "free_x")
```

#### Perishable

- 25% of items are perishable

```{r}
items %>% 
  count(perishable) %>% 
  mutate(pct = scales::percent(n/sum(n))) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()
```

## Promotions

```{r}
train %>% 
  left_join(stores, by = "store_nbr") %>% 
  group_by(store_nbr, type, onpromotion) %>% 
  summarise(median_units = median(unit_sales),
            .groups = "drop") %>% 
  mutate(onpromotion = case_when(
    onpromotion ~ "Promotoion",
    !onpromotion ~ "Standard",
    is.na(onpromotion) ~ "Missing",
    TRUE ~ "Err")) %>% 
  pivot_wider(names_from = onpromotion, values_from = median_units) %>% 
  pivot_longer(cols = c(Promotoion, Missing)) %>% 
  mutate(difference = value - Standard,
         store_nbr = fct_reorder(factor(store_nbr), difference, sum)) %>% 
  ggplot(aes(x = difference, y = store_nbr, col = name)) +
  geom_point() +
  geom_vline(xintercept = 0) +
  facet_grid(type~., scales = "free_y")
```

### Holidays

```{r}
holidays %>% 
  mutate(locale_extra = if_else(locale == "Local", locale_name,locale)) %>% 
  ggplot(aes(x = yday(date), y = locale_extra,col = factor(year(date)))) +
  geom_point() +
  scale_color_brewer(palette = 2) + 
  labs(x = "Day of the year (1-366)",
       y = "Locale",
       col = "Year",
       title = "Timing of holidays") +
  theme(plot.title = element_text(hjust = 0.5))
```

#### Joining holidays to data set

 - There's no common named key to join the holidays by locale

```{r}
holidays %>%
  mutate(tbl = "h") %>% 
  full_join(stores %>% mutate(tbl = "s"),
            by = c("locale_name" = "city")) %>% 
  count(tbl.x, tbl.y)
```

### Pay day
From the Kaggle comp - "Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this."

- Appears that this has a minor effect on the total sales, when looking at all sales. The effect might be different in different item types.

```{r}
train %>% 
  mutate(pay_day = if_else(date == ceiling_date(date, "month") - days(1) | day(date) == 15,1,0)) %>%
  count(date, pay_day, wt = unit_sales) %>% 
  ggplot(aes(x = wday(date,label = T), y = n, col = factor(pay_day))) +
  geom_boxplot()
```

